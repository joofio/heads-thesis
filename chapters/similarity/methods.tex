% !TeX root = ../../thesis.tex

For this work, our goal is to test several metrics based on the ranking of feature importance of a trained model. Normalized Discounted Cumulative Gain (NDCG) \cite{wangTheoreticalAnalysisNDCG} which is the sum of the true scores ranked in the order induced by the predicted scores, after applying a logarithmic discount. Then divide by the best possible score to obtain a score between 0 and 1. It is calculated by
\[
\text{{NDGC}} = \frac{{\text{{DCG}}(P)}}{{\text{{IDCG}}(P)}}
\]
where $\text{{DCG}}(P)$ is the Discounted Cumulative Gain and $\text{{IDCG}}(P)$ is the Ideal Discounted Cumulative Gain. 

\begin{small}    
    \begin{table}[H]
        \footnotesize
            \caption{Descriptive statistics of datasets used. Mean (Standard Deviation) for continuous variables. Mode [nr categories] for categorical variables.}\label{tab:descrptive_feature}
                \begin{tabularx}{\textwidth}{lXll|lXll}
                    \toprule
                Dataset & Column                         & Statistic    & \% Nulls & Dataset & Column          & Statistic    & \% Nulls \\
                \midrule
                heart   & Age                            & 54.4 (9.0)   & 0.0      & liver   & gammagt         & 38.3 (39.3)  & 0.0      \\
                heart   & sex                            & 1.0 {[}2{]}  & 0.0      & liver   & drinks          & 3.5 (3.3)    & 0.0      \\
                heart   & cp                             & 4.0 {[}4{]}  & 0.0      & liver   & Selector        & 2 {[}2{]}    & 0.0      \\
                heart   & trestbps                       & 131.7 (17.6) & 0.0      & thyroid & Class           & 1 {[}3{]}    & 0.0      \\
                heart   & chol                           & 246.7 (51.8) & 0.0      & thyroid & T3              & 109.6 (13.1) & 0.0      \\
                heart   & fbs                            & 0.0 {[}2{]}  & 0.0      & thyroid & TST             & 9.8 (4.7)    & 0.0      \\
                heart   & restecg                        & 0.0 {[}3{]}  & 0.0      & thyroid & TSTRI           & 2.1 (1.4)    & 0.0      \\
                heart   & thalach                        & 149.6 (22.9) & 0.0      & thyroid & TSH             & 2.9 (6.1)    & 0.0      \\
                heart   & exang                          & 0.0 {[}2{]}  & 0.0      & thyroid & TMAX            & 4.2 (8.1)    & 0.0      \\
                heart   & oldpeak                        & 1.0 (1.2)    & 0.0      & tumour   & class           & 1 {[}21{]}   & 0.0      \\
                heart   & slope                          & 1.0 {[}3{]}  & 0.0      & tumour   & age             & 2 {[}3{]}    & 0.0      \\
                heart   & ca                             & 0.0 {[}4{]}  & 1.3      & tumour   & sex             & 2 {[}2{]}    & 0.3      \\
                heart   & thal                           & 3.0 {[}3{]}  & 0.7      & tumour   & histologic-type & 2 {[}3{]}    & 19.8     \\
                heart   & num                            & 0 {[}5{]}    & 0.0      & tumour   & degree-of-diffe & 3 {[}3{]}    & 45.7     \\
                breast  & Clump Thickness               & 4.4 (2.8)    & 0.0      & tumour   & bone            & 2 {[}2{]}    & 0.0      \\
                breast  & Uniformity of Cell Size     & 3.1 (3.1)    & 0.0      & tumour   & bone-marrow     & 2 {[}2{]}    & 0.0      \\
                breast  & Uniformity of Cell Shape    & 3.2 (3.0)    & 0.0      & tumour   & lung            & 2 {[}2{]}    & 0.0      \\
                breast  & Marginal Adhesion             & 2.8 (2.9)    & 0.0      & tumour   & pleura          & 2 {[}2{]}    & 0.0      \\
                breast  & Single Epithelial Cell Size & 3.2 (2.2)    & 0.0      & tumour   & peritoneum      & 2 {[}2{]}    & 0.0      \\
                breast  & Bare Nuclei                   & 3.5 (3.6)    & 2.3      & tumour   & liver           & 2 {[}2{]}    & 0.0      \\
                breast  & Bland Chromatin               & 3.4 (2.4)    & 0.0      & tumour   & brain           & 2 {[}2{]}    & 0.0      \\
                breast  & Normal Nucleoli               & 2.9 (3.1)    & 0.0      & tumour   & skin            & 2 {[}2{]}    & 0.3      \\
                breast  & Mitoses                        & 1.6 (1.7)    & 0.0      & tumour   & neck            & 2 {[}2{]}    & 0.0      \\
                breast  & Class                          & 2 {[}2{]}    & 0.0      & tumour   & supraclavicular & 2 {[}2{]}    & 0.0      \\
                liver   & mcv                            & 90.2 (4.4)   & 0.0      & tumour   & axillar         & 2 {[}2{]}    & 0.3      \\
                liver   & alkphos                        & 69.9 (18.3)  & 0.0      & tumour   & mediastinum     & 2 {[}2{]}    & 0.0      \\
                liver   & sgpt                           & 30.4 (19.5)  & 0.0      & tumour   & abdominal       & 2 {[}2{]}    & 0.0      \\
                liver   & sgot                           & 24.6 (10.1)  & 0.0      &         &                 &              &          \\
                  \bottomrule
                \end{tabularx}
    
            \end{table}
        \end{small}
Cohen's kappa coefficient \cite{doi:10.1177/001316446002000104}  is a statistic that is commonly used to assess the level of agreement between two or more raters or evaluators who are providing categorical ratings or rankings of a set of items. So, we want to use to assess if it could be of use to check how similar the ranking of the features is, using the numbers as categorical.
\[
\kappa = \frac{{P_o - P_e}}{{1 - P_e}}
\]

where \(P_o\) is the observed agreement between the two raters and \(P_e\) is the expected agreement between the two raters by chance.



We also intend to use the $R^2$ to check if the explainability changes across datasets.
\[
R^2 = 1 - \frac{{\sum_{i=1}^n (y_i - \hat{y}_i)^2}}{{\sum_{i=1}^n (y_i - \bar{y})^2}}
\]

where \(y_i\) are the observed values of the dependent variable, \(\hat{y}_i\) are the predicted values of the dependent variable, \(\bar{y}\) is the mean of the observed values of the dependent variable and \(n\) is the number of data points.

Then we intend to use ranking metrics, namely Kendall tau, weighted Kendall tau and \ac{rbo}.
Kendall tau is a measure of correlation that measures the similarity between two rankings. It is commonly used in statistics and data analysis to evaluate the agreement or disagreement between two sets of rankings.

The Kendall tau coefficient \cite{kendallTreatmentTiesRanking1945} is defined as the difference between the number of concordant and discordant pairs of observations, divided by the total number of pairs. A concordant pair is a pair of observations that have the same ranking order in both sets, while a discordant pair is a pair of observations that have opposite ranking orders. The Kendall tau coefficient ranges from -1 to 1, where -1 represents perfect negative correlation, 0 represents no correlation, and 1 represents perfect positive correlation. 
\[
\tau = \frac{{\text{{number of concordant pairs}} - \text{{number of discordant pairs}}}}{{\text{{total number of pairs}}}}
\]


Weighted Kendall tau  \cite{vignaWeightedCorrelationIndex2015} is an extension of Kendall tau that takes into account the importance or weight of each observation in the rankings. In some cases, some observations may be more important than others, and their positions in the ranking may have a greater impact on the overall correlation. Weighted Kendall tau assigns a weight to each observation, and the correlation is calculated based on the weighted concordant and discordant pairs.
\[
\tau_w = \frac{{\sum_{i<j} w_{ij} \cdot sgn(x_i - x_j)}}{{\sum_{i<j} w_{ij}}}
\]
where $w_{ij}$ is the weight associated with the pair $(x_i, x_j)$ and $sgn(\cdot)$ is the sign function.

The \ac{rbo} \cite{webberSimilarityMeasureIndefinite2010} is a measure used to compare the similarity of two ranked lists, especially when these lists are of different lengths or have only partial overlap. The \ac{rbo} value ranges from 0 (no overlap) to 1 (complete agreement). One of the key features of \ac{rbo} is that it gives more weight to the top-ranked items. The formula for \ac{rbo} at a given depth \( d \) is as follows:

\[
RBO_d = (1 - p) \sum_{k=1}^{d} \left[ p^{k-1} \cdot \frac{|S_{k} \cap T_{k}|}{k} \right]
\]

Where  \( S_{k} \) and \( T_{k} \) are the sets of elements in the top \( k \) positions of the two ranked lists \( S \) and \( T \) respectively, \( |S_{k} \cap T_{k}| \) is the size of the intersection of these top \( k \) elements, \( p \) is a persistence parameter (usually between 0 and 1) that determines the weight given to the rankings at different depths. A lower value of \( p \) gives more weight to the top-ranked items and \( d \) is the depth to which you are calculating the \ac{rbo}, which can be up to the length of the longest list. This formula calculates the \ac{rbo} up to a finite depth \( d \). The parameter \( p \) is crucial as it models the user's persistence in considering the rankings down the list. The higher the value of \( p \), the more the metric considers items further down the list. 


Finally, we intend to use text-distance metrics. The theory behind this experiment is to treat the ordered columns in a ranking manner and apply text-distance metrics to check the distance between the two. Levenshtein distance \cite{navarroGuidedTourApproximate2001} is the minimum number of single-character insertions, deletions, or substitutions required to transform one string into another. Damerau-Levenshtein distance \cite{navarroGuidedTourApproximate2001} is similar to Levenshtein distance but also includes the transposition of two adjacent characters as an allowable operation. The hamming distance \cite{6772729} is a measure of the difference between two strings of equal length, defined as the number of positions at which the corresponding symbols are different. Jaro-Winkler distance \cite{navarroGuidedTourApproximate2001} is a string similarity measure that takes into account the number of matching characters, the number of transpositions, and the length of common prefixes, with a higher weight given to the common prefix.




\begin{algorithm}[hbtp]
\small
\SetAlgoLined

\For {dataset in datasets list}{
    create two copies of dataset, one that remains the same and a second to be disturbed with permutation \\
\For {ML algorithms in ML algorithms}{
\For {i in number of columns to test}{
\For {rep in  10 repetitions}{ 
create second dataset by permutating values in i columns in the first dataset
\For {target in dataset columns}{
\begin{itemize}
    \item Train-Test Split (95:5) for both
    \item model fit to train for both
    \item get feature importance per column for both
    \item Create an ordered rank of features for both
    \item Create new metrics values by comparing the results from both
    \item make cross-classification to compare with feature importance metrics
    \item aggregate results per metric 
\end{itemize}

 }
 }}}}

 \caption{Testing similarity scores in tabular datasets. Dataset list is the 5 datasets used in this work. \Ac{ml} algorithms are the 6 algorithms used in this work. Number of columns to test is the number of columns in the dataset. 10 repetitions is the number of times the columns are permutated.}\label{alg:simil_1}
\end{algorithm}


Like seen in algorithm~\ref{alg:simil_1}, the \ac{cc} was performed several times and according to the image~\ref{fig:cross_classi1}, we trained the model on dataset1 and tested on dataset1 and 2 and compared the results. However, we applied this twice; 1) where dataset1 is the original dataset and the dataset2 is the permutated/synthetic (RS) and 2) where dataset1 is the permutated/synthetic and dataset2 is the real one or original (SR). Both are examples of \acl{cc}.

The algorithms chosen were decision trees with \textit{gini} entropy function for decision making on splits on classification and squared error for regression; random forests with 100 trees and \textit{gini} criterion for classification and squared error for regression; support vector machines with C-support Vector classification and Epsilon-Support Vector Regression, \ac{knn} with 5 neighbours and uniform weights, linear regression/logistic regression and gaussian naive bayes for classification and Bayesian ridge with 300 maximum iterations and $\alpha$ and $\lambda$ of $1e^{-6}$. All of these were used as implemented in the \textit{scikit-learn} package \cite{scikit-learn}. The hyperparameters chosen were the default ones. We felt that tuning was not necessary here to test our hypothesis, since it is based on the ratio of results.
The text distance metrics were implemented by the text-distance package \cite{orsiniumTextdistanceComputeDistance}. Kendall tau, weighted Kendall tau were used as implemented by \textit{scipy} \cite{virtanenSciPyFundamentalAlgorithms2020a} and \ac{rbo}, as implemented in \cite{chenRankbiasedOverlapRBO2023}.
The methods chosen for creating several synthetic datasets were the synthpop package \cite{synthpop} with "cart" method, which is rpart implementation of a CART model. We also used  the SDV package \cite{SDV} to leverage their implementation of the CTGAN and Gaussian Copula to create 2 more synthetic datasets to test different methodologies of synthetic data creation.






