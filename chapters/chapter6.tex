% !TeX root = ../thesis.tex

\begin{savequote}[75mm]
We never are definitely right, we can only be sure we are wrong.
\qauthor{Richard P. Feynman}
\end{savequote}
\chapter{Discussion} \label{chap:disc}

%frases mt curtas


\initial{E}xtracting knowledge from healthcare data is a complex and multifaceted challenge. This endeavor is contingent upon the availability and the interpretability of data. In this chapter, we delve into the key contributions of this thesis and the primary challenges encountered throughout the work, elucidating how these obstacles were navigated. \\

This thesis contributed to supporting the fact that generating synthetic data is not as easy as it may seem at first glance and it's not the silver bullet as advertised in some settings. The need for robust evaluation metrics, especially for tabular datasets, is still present. The fact that the current ones are similar to those used in the generators (i.e., \acp{gan}) can introduce a significant bias. The old saying that states that when a metric becomes a goal, it stops being the appropriate metric fits here perfectly. But not all are bad news. Synthetic data has its place in healthcare and can serve many purposes. Synthetic data, even with very low utility (as in the sense used throughout the thesis, like similarity to the original), can still be useful. Having a broad idea of how the variables are distributed, the possible categories, and a generic idea of null values can go a long way to accelerate data analysis. We would certainly enjoy that at least in the works stated in sections \ref{subsec:distributed}, \ref{subsec:ipop} and \ref{subsec:obs}. \\

Another contribution lies in the fact that we can implement several mechanisms to extract knowledge from data without taking the data from its original repositories. We have proved that distributed learning is not inferior to the gold standard (centralized) or to the local counterparts. We also showed that we can even compare performance across hospitals or health institutions, without sharing the actual values, which certainly will be appreciated by many boards. The technology is here, evidence exists, it's a matter of implementation, trust, and engineering. \\

Finally, we have shown (like others before us) that we can use data to support clinical decision-making. However, we have also seen that the path from data to decision-making is not as easy as it may seem. We need to have a robust infrastructure, a trust framework, and a legal and technical framework to support the tools developed. We need to have the clinicians involved in the process, and we need to have the tools be as transparent and explainable as possible. We need to have the tools be reliable and accountable. We need to have the tools be easy to use and to understand. We need to have the tools be useful. We need to have the tools be impactful. We need to have the tools be ethical. We need to have the tools be safe. We need to have the tools be innovative. We need to have the tools be the future of healthcare. We need to have the tools be the future of healthcare data science. This is all we need. \\

There could even be the argument that implementing a \ac{cdss} should be as hard as implementing a new drug. The impact of a \ac{cdss} could be as big as a new drug, and the risks could be as big as well. Should we implement \ac{rct} to prove the effectiveness of such systems? Or, like first discussed in chapter \ref{chap:intro}, we can use observational data to support the claims of efficacy. This leads to the final contribution where we tried to use novel approaches to data analysis and provide claims of causality using observational data based real-world data. Mechanisms like \ac{iptw} are useful and can provide insights into the causality framework of treatments. Personally, I do not believe we are \textbf{there} yet, but I would argue that we are close.\\
The following sections will go deeper on the limitation, hurdles and methods we employed to surpass them.


\section{Accessing Data}
The first problem is getting access to data. The data is not always available, and when it is, it is not always in the format we need. Ethics committees and \ac{dpo} requirements are put in place in order to guarantee the patient's privacy and security, but a lot of times at the cost of timely access to data. We consider that synthetic data can have a good impact on this work. While we can leave the legal processes be, we may use synthetic data with a heavy focus on security to develop and test our algorithms. This is a very promising area of research, and we believe it will be a game-changer in the future.
Parallel to this approach are distributed paradigms. Having a distributed approach to data analysis could be of great help. This would allow for the data to be analysed in its original location in a more secure way and timely manner. If metrics and models could be built by local teams and shared across regions and/or countries to leverage the power of the many for single institutions could be groundbreaking. However, underlying both these approaches are data dictionaries and data governance tools. Having the correct functional/clinical description of data could be of great impact on the usage of data. Having already the variables defined as categorical, numerical and so on could be of great help. This is a very important aspect of data science, and it is often overlooked. Simple statistics of datasets could be useful as well. For example, the number of missing values, the number of unique values, the number of outliers, and so on. This would help the data scientist to understand the data better and to know what to expect from it. 

\section{Data Quality}
This point relates to the second big hurdle of knowledge extraction from healthcare data - quality. As discussed in section \ref{subsec:dq}, this is a very complex and sometimes elusive concept. In our case, this implied a lot of time spent with data preprocessing. We had to deal with missing values, outliers, and correctness in the context of the records, and data in different formats. We also had to link together different databases from different \acp{his} which brought to light new problems like the new dimensions of correctness of data. There is a common saying that sums this pretty well \textit{When we have one watch, we know the time, but when we have two, we may never know}. So if we had different information regarding the same variable in different systems, how to decide what is true?
Another aspect that is often overlooked is the relationship with the clinicians. We need to understand that they are the ones who will use the tools we develop, and they need to be involved in the process. We need to understand their needs and their workflow. Furthermore, we need to understand what they need and how they need it. We need to understand that they are not data scientists, and they do not have the time to learn how to use our tools. We need to make it easy for them to use our tools. Now healthcare is often explained in terms of clinical teams of different backgrounds. A similar concept could be beneficial for harvesting knowledge from data.


\section{Building robust software to support AI}
Building software or tools based on this data is still an early subject that possibly requires a legal and technical framework. A legal is connected to the impact of such tools in healthcare. If drugs require such a long time to be approved in order to assess security, how can we approve a tool that can have a similar impact? A technical framework is connected to the fact that we are still in the early stages of a new \ac{heads} paradigm. We are still trying to understand how to use data, and how to extract knowledge from it. We are still trying to understand how to evaluate the performance of our tools.  We are still trying to understand how to evaluate the impact of our tools in healthcare in a timely manner in a way that is not biased and that is not too expensive. Imposing similar structures to drugs is ill-advised since it could possibly kill the innovation potential and the interest in providing such tools. And this is where a quality infrastructure could be of use. Seriously betting of biomedical informatics could render huge payoffs down the line. Having the human and material resources to build data infrastructures on local (healthcare institutions) and regional, or even country-wise or cross-country policies to use effective use healthcare data is essential. At the time of the writing of this thesis, examples like \ac{ehds} are very promising initiatives that could help to overcome the hurdles of data availability and quality. However, cross-country initiatives will always be as good as the weakest link, so it is important to have a common framework and a common goal and to have the resources to achieve it. In concrete, having data pipelines, data governance and data interoperability tools, and data quality tools are essential. Having a common data dictionary and a common data format would also be of great help. This would allow for a more efficient use of data, and it would allow for the use of healthcare data to drive innovation.
Tightly connected with this is the possibility of having \ac{rwe} support clinical decisions live. Having data like the one produced in \ref{subsec:ipop} in real-time or with high update frequency could be leveraged in order to further support clinicians in making decisions based on data. However, we would require not only the premises already discussed, like data quality and cross-collaboration clinics, but a trust-framework would also be necessary. In order to make the automatic dashboard and metrics reliable, transparency is key. Having explainability and transparency in the process of evidence production will be key to building trust and accountability.


\section{Evaluation of AI tools}
The challenges of extracting knowledge from healthcare data are multi-faceted, as evident from the issues of data access, quality, and the complex relationship with clinicians. Another vital aspect is the integration of \ac{rwe} into clinical decision-making processes. \ac{rwe}, derived from data collected outside controlled clinical trials, offers immense potential for informing healthcare decisions. However, its integration requires meticulous attention to data quality, governance, and transparency. As healthcare data becomes increasingly digitized and voluminous, the opportunity to leverage \ac{rwe} in real-time or with high-frequency updates grows. This could significantly enhance the ability of clinicians to make data-driven decisions. However, for \ac{rwe} to be effectively integrated, it necessitates not only robust data infrastructure but also a trust framework. Clinicians and patients alike must have confidence in the accuracy, reliability, and transparency of the data and the algorithms used. Building this trust involves ensuring that data processing and decision-making algorithms are transparent and explainable, fostering a sense of accountability and reliability in the system.

Furthermore, the evolution of healthcare data science underscores the need for a comprehensive legal and technical framework. The comparison to drug approval processes highlights the importance of stringent evaluation for healthcare tools, balancing safety and innovation. The legal framework should address the ethical implications and societal impact of these tools, while the technical framework should focus on performance evaluation, data extraction techniques, and impact assessment. Establishing such frameworks is crucial for navigating the complexities of \ac{heads} and for fostering an environment where innovation can thrive without compromising patient safety or data integrity. This approach also involves the creation of quality infrastructures, emphasizing biomedical informatics, and developing robust data infrastructures at various levels, from local healthcare institutions to regional and international collaborations.

\section{Cross-disciplinary collaboration}
The future trajectory of healthcare data science is heavily reliant on cross-disciplinary collaboration and shared frameworks. Initiatives like the \ac{ehds} signify positive strides towards enhanced data availability and quality through collaborative efforts. However, the efficacy of such initiatives is contingent upon the uniformity of standards, shared objectives, and adequate resourcing among all participating entities. Essential measures include establishing common data dictionaries, formats, and interoperability tools. These collaborative endeavors are pivotal in streamlining data usage, thereby catalyzing innovation in healthcare. An integrative approach, melding technical expertise with legal and ethical considerations, is crucial for harnessing the full potential of healthcare data in improving patient outcomes and advancing medical science.


\section{Summing up}

In conclusion, this thesis presents a comprehensive examination of the multifarious aspects involved in harnessing healthcare data for knowledge extraction. The identified challenges and proposed solutions underscore the intricate interplay between data accessibility, quality, and interdisciplinary collaboration. The synthesis of this research contributes significantly to the field, providing a nuanced understanding of the complexities involved in leveraging healthcare data. This work not only advances academic knowledge but also holds the potential to inform and transform practical applications in healthcare, ultimately aiming to enhance patient care and outcomes.



%data quality é um sério problema - buscar papers ricardo e isso
%data dictionary é vital
%relacao com medicos é vital
%synthetic data é mirage - mas pode ser util por contexto - IPOP
%Metricas de avaliação sao fundamentais, nao conseguimos gerir o que nao conseguimos medir
%focar no impacto
%usar métodos alternativos - distribuido, p.ex.
%metodos de analise em tempo real de eficácia medicamentos - mt trabalho manual
%data engineering, preprocessing - é super dificil e de facto demora muito mais tempo.

