\begin{savequote}[75mm]
We never are definitely right, we can only be sure we are wrong.
\qauthor{Richard P. Feynman}
\end{savequote}
\chapter{Discussion} \label{chap:disc}

%frases mt curtas

Extracting knowledge from healthcare data is a complex and multifaceted challenge. This endeavor is contingent upon the availability and the interpretability of data. In this chapter, we delve into the primary challenges encountered in this thesis, elucidating how these obstacles were navigated. Additionally, we scrutinize the limitations inherent in the current methodologies for discovery, summarization, and application of knowledge derived from health data. Conclusively, this discourse highlights the seminal contributions of this thesis in enhancing healthcare quality through innovative data utilization strategies.

\section{Accessing Data}
The first problem is getting access to data. The data is not always available, and when it is, it is not always in the format we need. Ethics committees and \ac{dpo} requirements are put in place in order to guarantee the patient's privacy and security, but a lot of times at the cost of timely access to data. We consider that synthetic data can have a good impact on this work. While we can leave the legal processes be, we may use synthetic data with a heavy focus on security to develop and test our algorithms. This is a very promising area of research, and we believe it will be a game-changer in the future.
Parallel to this approach are distributed paradigms. Having a distributed approach to data analysis could be of great help. This would allow for the data to be analysed in its original location in a more secure way and timely manner. If metrics and models could be built by local teams and shared across regions and/or countries to leverage the power of the many for single institutions could be groundbreaking. However, underlying both these approaches are data dictionaries and data governance tools. Having the correct functional/clinical description of data could be of great impact on the usage of data. Having already the variables defined as categorical, numerical and so on could be of great help. This is a very important aspect of data science, and it is often overlooked. Simple statistics of datasets could be useful as well. For example, the number of missing values, the number of unique values, the number of outliers, and so on. This would help the data scientist to understand the data better and to know what to expect from it. 

\section{Data Quality}

The previous point relates to the second big hurdle of knowledge extraction from healthcare data - quality. As discussed in section \ref{subsec:dq}, this is a very complex and sometimes elusive concept. In our case, this implied a lot of time spent with data preprocessing. We had to deal with missing values, outliers, and correctness in the context of the records, and data in different formats. We also had to link together different databases from different \acp{his} which brought to light new problems like the new dimensions of correctness of data. There is a common saying that sums this pretty well \textit{When we have one watch, we know the time, but when we have two, we may never know}. So if we had different information regarding the same variable in different systems, how to decide what is true?
Another aspect that is often overlooked is the relationship with the clinicians. We need to understand that they are the ones who will use the tools we develop, and they need to be involved in the process. We need to understand their needs and their workflow. Furthermore, we need to understand what they need and how they need it. We need to understand that they are not data scientists, and they do not have the time to learn how to use our tools. We need to make it easy for them to use our tools. Now healthcare is often explained in terms of clinical teams of different backgrounds. A similar concept could be beneficial for harvesting knowledge from data.


\section{Building robust software to support AI}
Thirdly, building software or tools based on this data is still an early subject that possibly requires a legal and technical framework. A legal is connected to the impact of such tools in healthcare. If drugs require such a long time to be approved in order to assess security, how can we approve a tool that can have a similar impact? A technical framework is connected to the fact that we are still in the early stages of a new \ac{heads} paradigm. We are still trying to understand how to use data, and how to extract knowledge from it. We are still trying to understand how to evaluate the performance of our tools.  We are still trying to understand how to evaluate the impact of our tools in healthcare in a timely manner in a way that is not biased and that is not too expensive. Imposing similar structures to drugs is ill-advised since it could possibly kill the innovation potential and the interest in providing such tools. And this is where a quality infrastructure could be of use. Seriously betting of biomedical informatics could render huge payoffs down the line. Having the human and material resources to build data infrastructures on local (healthcare institutions) and regional, or even country-wise or cross-country policies to use effective use healthcare data is essential. At the time of the writing of this thesis, examples like \ac{ehds} are very promising initiatives that could help to overcome the hurdles of data availability and quality. However, cross-country initiatives will always be as good as the weakest link, so it is important to have a common framework and a common goal and to have the resources to achieve it. In concrete, having data pipelines, data governance and data interoperability tools, and data quality tools are essential. Having a common data dictionary and a common data format would also be of great help. This would allow for a more efficient use of data, and it would allow for the use of healthcare data to drive innovation.
Tightly connected with this is the possibility of having \ac{rwe} support clinical decisions live. Having data like the one produced in \ref{subsec:ipop} in real-time or with high update frequency could be leveraged in order to further support clinicians in making decisions based on data. However, we would require not only the premisses already discussed, like data quality and cross-collaboration clinics, but a trust-framework would also be necessary. In order to make the automatic dashboard and metrics reliable, transparency is key. Having explainability and transparency in the process of evidence production will be key to building trust and accountability.


\section{Evaluation of AI tools}
The challenges of extracting knowledge from healthcare data are multi-faceted, as evident from the issues of data access, quality, and the complex relationship with clinicians. Another vital aspect is the integration of real-world evidence (RWE) into clinical decision-making processes. RWE, derived from data collected outside of controlled clinical trials, offers immense potential for informing healthcare decisions. However, its integration requires meticulous attention to data quality, governance, and transparency. As healthcare data becomes increasingly digitized and voluminous, the opportunity to leverage RWE in real-time or with high-frequency updates grows. This could significantly enhance the ability of clinicians to make data-driven decisions. However, for RWE to be effectively integrated, it necessitates not only robust data infrastructure but also a trust framework. Clinicians and patients alike must have confidence in the accuracy, reliability, and transparency of the data and the algorithms used. Building this trust involves ensuring that data processing and decision-making algorithms are transparent and explainable, fostering a sense of accountability and reliability in the system.

Furthermore, the evolution of healthcare data science underscores the need for a comprehensive legal and technical framework. The comparison to drug approval processes highlights the importance of stringent evaluation for healthcare tools, balancing safety and innovation. The legal framework should address the ethical implications and societal impact of these tools, while the technical framework should focus on performance evaluation, data extraction techniques, and impact assessment. Establishing such frameworks is crucial for navigating the complexities of \ac{heads} and for fostering an environment where innovation can thrive without compromising patient safety or data integrity. This approach also involves the creation of quality infrastructures, emphasizing biomedical informatics, and developing robust data infrastructures at various levels, from local healthcare institutions to regional and international collaborations.

\section{Cross-disciplinary collaboration}
The future trajectory of healthcare data science is heavily reliant on cross-disciplinary collaboration and shared frameworks. Initiatives like the \ac{ehds} signify positive strides towards enhanced data availability and quality through collaborative efforts. However, the efficacy of such initiatives is contingent upon the uniformity of standards, shared objectives, and adequate resourcing among all participating entities. Essential measures include establishing common data dictionaries, formats, and interoperability tools. These collaborative endeavors are pivotal in streamlining data usage, thereby catalyzing innovation in healthcare. An integrative approach, melding technical expertise with legal and ethical considerations, is crucial for harnessing the full potential of healthcare data in improving patient outcomes and advancing medical science.


In conclusion, this thesis presents a comprehensive examination of the multifarious aspects involved in harnessing healthcare data for knowledge extraction. The identified challenges and proposed solutions underscore the intricate interplay between data accessibility, quality, and interdisciplinary collaboration. The synthesis of this research contributes significantly to the field, providing a nuanced understanding of the complexities involved in leveraging healthcare data. This work not only advances academic knowledge but also holds the potential to inform and transform practical applications in healthcare, ultimately aiming to enhance patient care and outcomes.

%data quality é um sério problema - buscar papers ricardo e isso
%data dictionary é vital
%relacao com medicos é vital
%synthetic data é mirage - mas pode ser util por contexto - IPOP
%Metricas de avaliação sao fundamentais, nao conseguimos gerir o que nao conseguimos medir
%focar no impacto
%usar métodos alternativos - distribuido, p.ex.
%metodos de analise em tempo real de eficácia medicamentos - mt trabalho manual
%data engineering, preprocessing - é super dificil e de facto demora muito mais tempo.

