Distributed learning \cite{distributed} can be understood as training several models in a different setting and then aggregating them as a whole. There are two main branches of these approaches, distinguishable by the existence of a central orchestrator server: federated learning where such an entity exists, and peer-to-peer (or swarm) \cite{swarm_learning} learning where it does not. 
Even though distributed learning has been receiving a lot of attention recently, only some of its concepts have been focused on, mainly distributed-deep learning with a federated learning approach \cite{xuFederatedLearningHealthcare2021,leeFederatedLearningClinical2020}. These methods use the strength of neural networks and several algorithms like federated averaging to create distributed models capable of handling complex data like text, sound, or image \cite{prayitnoSystematicReviewFederated2021}. However, considering that there are great amounts of information, especially in healthcare, stored as tabular data \cite{alvarezsanchezTAQIHToolTabular2019,dimartinoExplainableAIClinical2022,payrovnaziriExplainableArtificialIntelligence2020} and that neural networks are often not the best tool for such data structures \cite{borisovDeepNeuralNetworks2022a}, there is a lack of knowledge in the traditional machine learning techniques in a distributed manner.
%Federated Learning was introduced in 2016 \cite{konecny_federated_2016,mcmahanFederatedLearningDeep2016} and it was called federated since "the learning task is solved by a loose federation of participating devices (which we refer to as clients) which are coordinated by a central server" \cite{konecny_federated_2016}. Federated learning has two main architectures: a) horizontal and b) vertical  \cite{yangFederatedMachineLearning2019b}. 
%Horizontal refers to having the same features in all silos, but different populations in each silo. Vertical refers to having different features across silos for the same population. Then we have other approaches that expand the concept of federated learning with previous machine learning and deep learning methodologies such as transfer learning, reinforcement learning \cite{liuSystematicLiteratureReview2020} and quantum machine-learning \cite{quantum-fed-ml}. 
%Federated learning can also be classified by the information flow. Model data can be shared only with the main central server, as in more traditional methods, but also being incremental, sharing data model sequentially between silos, with central server orchestration \cite{cyclic_distribution}. 

Nevertheless, there have been some health-related  distributed machine-learning projects successfully implemented, such as euroCAT  \cite{eurocat} which implemented an infrastructure across five clinics in three countries. \ac{svm} models were used to learn from the data distributed across the five clinics. Each clinic has a connector to the outside where only the model's parameters are passed to the central server which acts as a master deployer regarding the model training with the radiation oncology data.
Also, ukCAT \cite{ukcat} did similar work, with an added centralised database in the middle, but the training being done with a decentralized system.
%Other methods and approaches have been also evaluated such as the work of Brisimi et. al. \cite{brisimi_federated_2018}  for predicting hospitalisations or deep learning methods oriented to analysing medical imaging \cite{chang_distributed_2018}, evaluating histological samples \cite{pathology-fl} and finally, some preprints showing the impact of federated learning regarding COVID-19 prediction \cite{vaid_federated_2020}. For a sound review please redirect to Zerka et al. \cite{zerkaSystematicReviewPrivacyPreserving2020a}

Finally, a few works have explored the evaluation of models in a distributed manner, for example, comparing  centralised machine learning, distributed machine learning and federated learning on MNIST dataset \cite{performance_evaluation_1}. Also, works that evaluate federated learning on MNIST, MIMIC-III and PhysioNet ECG datasets, but not in comparison with other methods  \cite{performance_evaluation_2}. The work by Tuladhar and colleagues \cite{distributed} uses healthcare images and/or public and curated datasets.
As far as we know, this is the first time a distributed machine learning evaluation is done with real-world clinical data from several different data sources.