% !TeX root = ../../thesis.tex

%As the use of \ac{ai} is increasing in the healthcare space \cite{deep_learning_increase_health}, increased demand for ethical usage of personal patient data is occurring as well \cite{ehtical_use_ml}. This has been happening both on the governmental side, with several regulations passed to protect citizens' data and personal information (such as \ac{gdpr} in the \ac{eu} \cite{gdpr_article} and \ac{hipaa} in the \ac{us} \cite{hippa}), and on the public side, with an increased concern with continuous data breaches across institutions \cite{abdulrahmanSurveyFederatedLearning2021}. So,  we are now faced with a dilemma on a compromise between what is possible to do with the available data and what should be done regarding patient privacy \cite{swarm_learning}. This is the main reason why health institutions implement burdensome processes and methodologies for sharing patient data, often costing a great deal of time, money, and human resources, seldomly overtaking the ideal time frame for analysing such data.
%Due to these privacy concerns, the traditional method for using data in healthcare is, nowadays, by focusing on data from a single institution in order to predict or infer something regarding those patients; this could be understood as local learning. This approach has some drawbacks, namely data quantity, data quality and possible class imbalance \cite{rajkomarMachineLearningMedicine2019}, never quite raising into its full potential for promoting best healthcare practices
%\cite{federated_healthcare_informatics,usage_ai_healthcare,wangAIHealthState2019} with data sharing between institutions.
%In order to overcome this issue, there are a few, more complex, systems that aggregate data from several institutions, so more robust algorithms could be trained. However, this globally centralised aggregation of data encompasses a very important data breach hazard. 

%This is the setting where distributed learning could create a greater impact. A halfway point between local and centralised learning is where we train several models, one in each institution (or silo), and where the sole information that leaves the premises is a trained model or its metadata. A distributed model is built as the aggregation of all the local models, consequently aiming to create a model similar to one globally trained with all the data in a centralised server. However, the distributed model never contacted with any data, only the local models did. This provides the opportunity to create better models, improve data protection, reduce training time and cost and provide better scaling capabilities  \cite{jatainContemplativePerspectiveFederated2021}.

%including federated-learning approaches, where a central system orchestrates the operation \cite{federated_learning_intro} or a swarm/peer-to-peer framework where silos communicate with each other. However,
%There are already some implementations of distributed systems in the healthcare space, but we lack a robust understanding of how these models behave with real data, when compared with the classical models built with all the aggregated data. Additionally, the main issues regarding the development and implementation of such systems in healthcare are still elusive.
%So we aim to understand how distributed mechanisms behave compared to using all data in the healthcare space and if they are a suitable replacement for traditional machine-learning pipelines. The contributions of this paper are:
%\begin{myitemize}
%    \item Understand how to address the lack of data quality of real-world data regarding distributed model creation;
%    \item Evaluate a distributed model against its local counterparts;
%    \item Measure the prediction performance difference between a distributed model and a centralised one;
%    \item Identify the capabilities of a distributed model to track population changes on the local datasets;
%    \item Open a research path for using distributed models to predict several target variables in obstetrics clinical research.
%\end{myitemize}



As the use of \ac{ai} is increasing in the healthcare space \cite{deep_learning_increase_health}, increased demand for ethical usage of personal patient data is occurring as well \cite{ehtical_use_ml}. This has been happening both on the governmental side, with several regulations passed to protect citizens' data and personal information (such as \ac{gdpr} in the \ac{eu} \cite{gdpr_article} and \ac{hipaa} in the \ac{us} \cite{hippa}), and on the public side, with an increased concern with continuous data breaches across institutions \cite{abdulrahmanSurveyFederatedLearning2021}.  So,  we are now faced with a dilemma on a compromise between what is possible to do with the available data and what should be done regarding patient privacy \cite{swarm_learning}. This is the main reason why health institutions implement burdensome processes and methodologies for sharing patient data, often costing a great deal of time, money, and human resources, seldomly overtaking the ideal time frame for analysing such data.
Due to these privacy concerns, the traditional method for using data in healthcare is, nowadays, by focusing on data from a single institution in order to predict or infer something regarding those patients; this could be understood as local learning. This approach has some drawbacks, namely data quantity, data quality and possible class imbalance \cite{rajkomarMachineLearningMedicine2019}, never quite raising into its full potential for promoting best healthcare practices
\cite{federated_healthcare_informatics,usage_ai_healthcare,wangAIHealthState2019} with data sharing between institutions.
In order to overcome this issue, there are a few, more complex, systems that aggregate data from several institutions, so more robust algorithms could be trained. However, this globally centralised aggregation of data encompasses a very important data breach hazard. 

This is the setting where distributed learning could create a greater impact. A halfway point between local and centralised learning is where we train several models, one in each institution (or silo), and where the sole information that leaves the premises is a trained model or its metadata. A distributed model is built as the aggregation of all the local models, consequently aiming to create a model similar to one globally trained with all the data in a centralised server. However, the distributed model never contacted with any data, only the local models did. This provides the opportunity to create better models, improve data protection, reduce training time and cost and provide better scaling capabilities  \cite{jatainContemplativePerspectiveFederated2021}.

%including federated-learning approaches, where a central system orchestrates the operation \cite{federated_learning_intro} or a swarm/peer-to-peer framework where silos communicate with each other. However,
%There are already some implementations of distributed systems in the healthcare space, but we lack a robust understanding of how these models behave with real data, when compared with the classical models built with all the aggregated data. So we aim to understand how distributed mechanisms behave compared to using all data in the healthcare space and if they are a suitable replacement for traditional machine-learning pipelines. The contributions of this paper are:

While numerous multi-institutional initiatives have successfully established integrated data repositories for healthcare research, there remains an incomplete understanding of the performance and scalability of distributed systems when directly compared to traditional, centralised models. Specifically, the nuanced behaviors of these distributed frameworks under real-world data conditions—contrasted against classical models that utilize aggregated data—have yet to be fully delineated. This paper aims to critically evaluate the efficacy and suitability of distributed mechanisms within the healthcare domain, assessing their potential as viable alternatives to conventional machine-learning pipelines. The contributions of this paper include:

\begin{myitemize}
    \item Evaluate a distributed model against its local counterparts;
    \item Measure the prediction performance difference between a distributed model and a centralised one;
%    \item Identify the capabilities of a distributed model to track population changes on the local datasets;
    %\item Understand how to address the lack of data quality of real-world data regarding distributed model creation;

  %  \item Open a research path for using distributed models to predict several target variables in obstetrics clinical research.
\end{myitemize}
