% !TeX root = ../thesis.tex

Using, once again, the tale of George Washington but now with a different purpose; the medical doctors in that region of the globe, at least, followed the theory of humours, which relied on the fact that a healthy human person was a balance between four humours (blood, phlegm, yellow bile, and black bile). So, the treatment for George Washington was to rebalance those four humours, and so, doctors needed to remove blood, which was the supposed cause of his illness. Since microbiology and its importance would only be discovered sometime after, the idea at the time was inspired by the fact that the imbalance of these four senses of humour and illness was present at the same time.

This is now known as a textbook definition of confounding correlation with causation. And in this subject in particular, it was not the imbalance in the humours that caused illness, but an illness that caused the imbalance.

So, this example shows that evidence without proper causality can lead to misguided results and mistrust.

That is why, nowadays, \ac{ebm} and \ac{xai} can be brought together and expanded through \ac{cml}. But what is causality? We could argue that it is related to something \textbf{causing} something else. This causal effect, especially in medicine, can be related to a comparison of the outcome a particular person would exhibit given a particular intervention and the outcome in the same person of the control intervention. This is particularly hard since we cannot do both things at the same time. This is the basis of why \acp{rct} are the gold standard of experimentation, since they are the current best tool to achieve something similar to this \cite{10.7551/mitpress/14244.001.0001}.

%- causality vs observation

\ac{cml} is a branch of \ac{ml} that focuses on understanding and quantifying causal relationships from data \cite{hernanDefinitionCausalEffect2004}. Instead of just finding patterns or correlations in data, \ac{cml} aims to uncover the cause-and-effect relationships that explain these patterns.
This is especially important since current or traditional \ac{ml} and \ac{ai} methodologies rely heavily on association and not causation. So, \ac{cml} can support traditional algorithms to solve its limitations \cite{pearlTheoreticalImpedimentsMachine2018}.
There are currently two main frameworks for trying to unveil causality in data: the \ac{scm}  and the \ac{pof} \cite{shiLearningCausalEffects2022b}. \textbf{\ac{scm}} relies on 1) Causal Graphs and 2) structural equations.

\begin{enumerate}
    \item Causal Graphs are based on \acp{dag}: These are graphical models used to represent causal relationships between different variables. The nodes in the graph represent variables, and the edges (arrows) between nodes represent causal relationships. For instance, an edge from Node A to Node B signifies that A has a causal effect on B. We should not confuse causal graphs with \ac{bn}. Even though both rely on \acp{dag}, Causal Graphs represent causal relationships, and \ac{bn} represent conditional dependencies.

    \item Structural Equations refer to a set of mathematical expressions that represent causal relationships between variables. These equations model the way changes in one variable, often termed the "cause," lead to changes in another, termed the "effect." Within a \ac{sem}, both observed and latent (unobserved) variables can be incorporated, and the causal pathways between them are explicitly defined. By employing \ac{sem} in \ac{cml}, researchers can elucidate intricate relationships among variables, disentangle direct from indirect effects, and infer causal mechanisms. This approach provides a more profound understanding of the underlying data-generating process, enabling better predictions and interventions in complex systems.

\end{enumerate}

\textbf{\Ac{pof}} model centres on the concept of potential outcomes which can be understood as all of the possible outcomes for a patient.  Each unit (e.g., a patient or a sample) has a set of potential outcomes, each corresponding to one of the possible treatments the unit could receive. The causal effect is defined as the difference between these potential outcomes. This framework allows for the formal definition and estimation of causal effects. In this approach, we consider the potential outcomes for each unit (for example, a patient in a healthcare context) under each possible treatment or intervention. Each unit has a set of potential outcomes corresponding to each possible intervention. However, we can only observe one of these outcomes for each unit, corresponding to the intervention that was actually received. The other outcomes, which would have occurred had different interventions been implemented, remain latent. These are known as counterfactual outcomes.

The difference between potential outcomes under different treatments represents the causal effect of the treatments. For instance, in a healthcare scenario, if we are studying the effect of a drug, we might consider two potential outcomes for each patient: the outcome if the patient is given the drug, and the outcome if the patient is not given the drug. The difference between these outcomes represents the causal effect of the drug on the patient. However, as we can only observe one of these outcomes for each patient (the one corresponding to the treatment they actually received), a key challenge in causal inference is estimating the unobserved potential outcomes. Various statistical methods, including randomized experiments, matching methods, and instrumental variable methods, can be used to estimate these unobserved potential outcomes.

\begin{enumerate}
    \item \textbf{Counterfactuals}: This is a concept rooted in the idea of "what-if" scenarios. A counterfactual outcome for a given individual is the outcome that would have occurred had the individual been exposed to a different treatment or condition.
    Counterfactuals play a pivotal role in the field of \ac{cml}, offering a sophisticated approach to understanding cause-and-effect relationships. In essence, a counterfactual is a conceptual device used to contemplate what would have happened under a different set of circumstances than what actually occurred. This hypothetical scenario is created by altering some aspect of the actual situation, providing a means of comparison to evaluate the effect of a particular variable or intervention.

    For instance, in the context of healthcare, consider a scenario where a patient was given a particular drug and recovered. The counterfactual question here would be: "What would have happened to the patient if they hadn't been given the drug?" Answering this question allows us to estimate the causal effect of the drug on the patient's recovery. While the true counterfactual outcome is unobservable (since we cannot rewind time and alter the decision), various statistical techniques, \ac{ml} algorithms, and experimental designs are employed in causal inference to estimate this effect as accurately as possible. The ability to make such counterfactual inferences is crucial in numerous fields, including medicine, economics, social sciences, and policy-making, where understanding causal relationships is paramount.
    
    \item \textbf{Instrumental Variables}: These are variables that are related to the treatment but not the outcome, except through their effect on the treatment \cite{burgessImprovingBiasCoverage2012,daviesIssuesReportingConduct2013}. They can be used to control for unmeasured confounding variables. \Acp{iv} are a powerful tool used in causal inference to help address the problem of confounding variables, especially in situations where randomization is not feasible. An instrumental variable is a variable that is correlated with the independent variable (the treatment) but does not directly affect the dependent variable (the outcome), except through its effect on the treatment. In other words, it is a variable that induces changes in the explanatory variable but is otherwise unrelated to the outcome of interest. The idea behind using an instrumental variable is to isolate the portion of the variation in the treatment that is independent of the confounders and therefore provides a "natural" form of randomization. The causal effect of the treatment on the outcome can then be estimated based on this variation.
    
    For example, in a study assessing the impact of education on income, it's challenging to identify causal effects because numerous unobserved factors (like ability or motivation) could affect both education and income, thus confounding the relationship. If we find an instrumental variable – say, distance to the nearest college (which affects the likelihood of getting higher education but doesn't directly affect income) – we can use this to isolate the part of the variation in education that is unrelated to the unobserved confounders, and thereby get a more accurate estimate of the causal effect of education on income.
    
    It's crucial, however, to remember that the use of instrumental variables relies on certain assumptions, such as the relevance and exogeneity of the \ac{iv}. The relevance assumption requires that the IV is correlated with the treatment, and the exogeneity assumption requires that the IV affects the outcome only through the treatment and is not related to the unobserved confounders. Violations of these assumptions can lead to biased and inconsistent estimates of causal effects.
    
    \item \textbf{Propensity Score}: This is the probability of a unit (e.g., a patient) being assigned to a particular treatment given a set of observed characteristics. Propensity scores are used to balance the characteristics of treatment and control groups, mimicking the conditions of a randomized experiment \cite{austinIntroductionPropensityScore2011b,austinPerformanceDifferentPropensityscore2010}
    %%%%
    
    The propensity score is a statistical concept widely used in causal inference, particularly in the field of observational studies where random assignment of treatment is not possible. The propensity score for an individual is the probability of receiving the treatment given the observed characteristics of that individual. In other words, it's the likelihood that a particular individual would be assigned to the treatment group based on their observed features.
    
    The key idea behind propensity scores is to create a balance between the treatment and control groups based on these observed characteristics, thus mimicking the conditions of a randomized controlled trial. This balance helps to eliminate bias caused by confounding variables, allowing for a more accurate estimate of the treatment effect. Once propensity scores are calculated, they can be used in several ways including matching, stratification, \ac{iptw}, and as covariates in regression adjustment.
    
    For example, consider a study investigating the effect of a training program on job outcomes. Individuals might self-select into the training program based on characteristics like motivation or prior education, which are also related to job outcomes, creating confounding. The propensity score, calculated based on these observed characteristics, can be used to match each participant in the training program with a similar non-participant or to weight the observations, such that the distribution of observed characteristics is similar between the groups. This helps to isolate the effect of the training program on job outcomes.
    

    After achieving this balance, it becomes more meaningful and less biased to estimate treatment effects, such as \ac{ate} and \ac{att}.

The \ac{ate} quantifies the difference in mean outcomes between units that are treated and units that are not. Essentially, it calculates the expected difference in outcomes if everyone in a population received a treatment versus if no one received it. Mathematically, the \ac{ate} is represented as:
\[ \text{ATE} = E[Y_1 - Y_0] \]
where \( Y_1 \) is the potential outcome under treatment and \( Y_0 \) is the potential outcome under control. The expectation is taken over the entire population.

After addressing confounding using propensity scores, the \ac{att} narrows its focus to the treated subpopulation. It measures the average effect of a treatment on those units that actually received the treatment, comparing their observed outcomes to what their outcomes would have been without the treatment. The formula for \ac{att} is:
\[ \text{ATT} = E[Y_1 - Y_0 | D = 1] \]
where \( Y_1 \) and \( Y_0 \) once more denote potential outcomes under treatment and control, respectively, and \( D \) is an indicator for treatment (with \( D = 1 \) indicating treatment).


    However, it's important to note that propensity scores only account for observed confounders. If there are unobserved confounders that influence both treatment assignment and the outcome, propensity score methods may still produce biased estimates of the causal effect.

\end{enumerate}